# lora可以参照这个文件：
simple_thu_chatglm6b\code02_训练模型全部流程.ipynb
这是参照上面这个文件稍微改了一些和数据相关的东西： simple_thu_chatglm6b\code02_训练模型全部流程.py
# 微调完以后拿这个inference：
simple_thu_chatglm6b\infer.ipynb 

这个history还要把它编码成一个字符串，然后他就把它问答round这样一个形式。你可以看到这个modelling ChatGLM这个点PY文件里面是有有写这个东西，所以肯定是把整个history都加上去的。